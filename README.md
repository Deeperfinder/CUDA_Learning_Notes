# CUDA_Learning_Notes
包含GEMM， FLash Attention的cute、cuda实现
## GEMM
- 目前在SM80上实现了Cute的简单GEMM  + 流水线GEMM（multi-stage）
* 通过python biding和torch load 来构建算子的benchmark

CUDA test 1 (naive / sliced k / cute / cublas)
```bash
------------------------------------GEMM lib build from sources-------------------------------------
----------------Loading hgemm lib on device: NVIDIA H20, capability: (9, 0), : None-----------------
----------------------------------------------------------------------------------------------------
---------------------------------------M=1024, N=1024, K=512----------------------------------------
                    (naive_fp16): ['-10.132812', '0.0       '], time:0.18ms, TFLOPS:5.89  (+0.00%)
   tn(cute+stage4+swizzle<smem>): ['-18.96875 ', '-15.523437'], time:0.03ms, TFLOPS:31.02 (+426.92%)
                        (cublas): ['27.875    ', '-8.6328125'], time:0.02ms, TFLOPS:62.00 (+99.85%)
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
---------------------------------------M=2048, N=2048, K=1024---------------------------------------
                    (naive_fp16): ['-33.9375  ', '0.0       '], time:1.31ms, TFLOPS:6.57  (+0.00%)
   tn(cute+stage4+swizzle<smem>): ['47.09375  ', '-36.4375  '], time:0.12ms, TFLOPS:73.32 (+1015.76%)
                        (cublas): ['-2.6796875', '42.75     '], time:0.07ms, TFLOPS:116.62(+59.05%)
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
---------------------------------------M=4096, N=4096, K=4096---------------------------------------
                    (naive_fp16): ['12.6640625', '-118.6875 '], time:42.11ms, TFLOPS:3.26  (+0.00%)
                 (sliced_k_fp16): ['12.6640625', '-118.6875 '], time:21.58ms, TFLOPS:6.37  (+95.08%)
   tn(cute+stage4+swizzle<smem>): ['72.3125   ', '85.4375   '], time:1.54ms, TFLOPS:89.41 (+1304.07%)
                        (cublas): ['12.3984375', '-120.125  '], time:0.98ms, TFLOPS:139.67(+56.22%)
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
---------------------------------------M=8192, N=8192, K=8192---------------------------------------
                    (naive_fp16): ['-113.75   ', '69.9375   '], time:425.29ms, TFLOPS:2.59  (+0.00%)
                 (sliced_k_fp16): ['-113.75   ', '69.9375   '], time:184.63ms, TFLOPS:5.96  (+130.35%)
   tn(cute+stage4+swizzle<smem>): ['4.7890625 ', '-94.25    '], time:11.76ms, TFLOPS:93.53 (+1470.47%)
                        (cublas): ['-114.5    ', '70.375    '], time:8.44ms, TFLOPS:130.29(+39.31%)
----------------------------------------------------------------------------------------------------
```

# 参考仓库
- https://github.com/reed-lau/cute-gemm
- https://github.com/xlite-dev/LeetCUDA